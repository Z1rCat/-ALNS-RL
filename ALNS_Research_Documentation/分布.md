
# “不确定性事件分布”数据流审计报告（不改代码版）

> 目标：回答“数据从哪里来、怎么被喂给训练/测试、ALNS 如何消费”三件事，并解释为什么你现在看不到每一步对应的“低压/高压分布”Ground Truth，以及在**不改代码**前提下能否恢复。

---

## 0. 结论摘要（先给你可执行的答案）

1. **混合分布数据不是写在一个大文件里**，而是按 `table_number=0..999` 生成 **1000 个独立 Excel 文件**：  
   `.../R{R}/Intermodal_EGS_data_dynamic_congestion{idx}.xlsx`（`idx` 就是 `table_number`）。
2. 每个文件里**只存了具体 duration 数值（以 `[start,end]` 字符串形式）**，**不包含** “来自低压还是高压分布”、“分布参数(mean/sigma)”等元数据。
3. **训练/实施阶段选文件的逻辑是“按索引顺序读”**（不是 shuffle 也不是随机）：  
   - 训练阶段：`table_number` 从 0 开始 `+1` 递增（0,1,2,...）  
   - 实施阶段：第一次切换时 `table_number=499`，之后 `-1` 递减（499,498,...）
4. 你现在想要的 “上帝视角：该 step 属于低压/高压”——**其实可以不改代码、用日志离线恢复**：  
   因为生成脚本对 mix 的实现是 **“前 N 个 idx 用分布A，后面用分布B（或三段）”**，没有打乱；而 `rl_trace.csv` 里已经有 `table_number`，run 的 `meta.json` 里有 `distribution`（如 `lognormal_mix_8_80_75_25`）。  
   所以你能用公式：  
   - `idx<table_boundary` → “第一段分布”  
   - `idx>=table_boundary` → “第二段分布”  
   直接给每一行日志打上 Ground Truth 标签。

下面我按你给的 3 步审计顺序展开，给出“数据流模型”。

---

## 1) 源头审计：数据的物理形态（生成端）

### 1.1 生成混合分布的逻辑在哪里？
文件：`codes/generate_mixed_parallel.py`

- 混合分布核心：`get_distribution_matrix()`（`codes/generate_mixed_parallel.py:61`）
- 单文件写入：`generate_single_file()`（`codes/generate_mixed_parallel.py:221`）

`mix` 的实现方式非常关键：它不是“每个样本随机抽一次来自哪个分布”，而是：

> **先生成一大块来自分布A的矩阵 rows，再生成一大块来自分布B的矩阵 rows，最后 `np.vstack` 拼起来。没有 shuffle。**

例如（按代码原样）：
- `normal_mix_8_80_75_25`：  
  - 前 `n1=int(total_files*0.75)` 行：`Normal(mean=8, std=2)`  
  - 后面：`Normal(mean=80, std=20)`  
- `lognormal_mix_8_80_75_25`：  
  - 前 75% 行：`LogNormal(mu=2, sigma=0.5)`  
  - 后 25% 行：`LogNormal(mu=4.4, sigma=0.5)`  
- 三段混合 `lognormal_mix_9_30_3_30_30_40`：  
  - 前 30%：`LogNormal(mu=log(9)-0.125, sigma=0.5)`  
  - 中 30%：`LogNormal(mu=log(30)-0.125, sigma=0.5)`  
  - 后 40%：`LogNormal(mu=log(3)-0.125, sigma=0.5)`

> 注意：`lognormal_mix_8_80_*` 的代码里用的是 `mu=2` 和 `mu=4.4`，理论均值分别约为 `exp(mu+sigma^2/2)`：  
> - `mu=2,sigma=0.5` → 均值 ≈ `exp(2.125)=8.37`（和“8”一致）  
> - `mu=4.4,sigma=0.5` → 均值 ≈ `exp(4.525)=92.4`（不严格等于“80”，命名更像“高压档”而不是精确 80）

### 1.2 1000 个样本是一个大文件还是 1000 个小文件？
**结论：1000 个独立小文件**。

在 `generate_single_file()` 中写死了文件名模板（`codes/generate_mixed_parallel.py:225`）：

- 文件名：`Intermodal_EGS_data_dynamic_congestion{idx}.xlsx`
- 输出目录：`.../{target_folder}/R{r}/`

master 会固定传 `--total_files 1000`，所以每个 R 会生成：
- `Intermodal_EGS_data_dynamic_congestion0.xlsx`
- `Intermodal_EGS_data_dynamic_congestion1.xlsx`
- ...
- `Intermodal_EGS_data_dynamic_congestion999.xlsx`

### 1.3 单个样本文件里面存了什么数据结构？
每个 `*.xlsx` 至少包含：
- 基础 sheets：`N`, `R_{r}`, `T`, `K`, `o`（用于静态问题数据）
- 动态事件 sheets：多个 `R_{r}_{start_t} (2)`（每个 sheet 2 行：拥堵 begin/finish）

动态事件 sheet 的结构是（由代码写入，`codes/generate_mixed_parallel.py:264` 附近）：

|列名|含义|
|---|---|
|uncertainty_index|事件编号（同一事件 begin/finish 共享一个编号）|
|type|`congestion` 或 `congestion_finish`|
|location_type|目前写死 `node`|
|vehicle|-1（占位）|
|location|节点编号|
|duration|字符串形式的列表，例如 `"[4, 13]"`|
|mode|运输模式标号|

**关键点：文件里只有“最终 duration 数值”**（以及由它计算的 end time），**没有保存 dist_name/均值/方差/来自哪一段**。

---

## 2) 调度审计：训练/测试（实施）阶段“喂数据”怎么选文件？

### 2.1 master 如何启动数据生成与仿真？
文件：`codes/Dynamic_master34959.py`

逻辑概括：
1. 选择 `dist_name` + `request_number(R)`（交互式菜单）
2. 调用生成器脚本：`generate_mixed_parallel.py`（固定生成 1000 文件）
3. 并行启动两条线程：  
   - approach=0：ALNS 仿真线程  
   - approach=1：RL 训练/实施线程  
（见 `codes/Dynamic_master34959.py` 的 `run_generator()` / `run_simulation()`）

### 2.2 “当前 episode 用哪个文件？”是谁决定的？
**决定者是 ALNS 线程**（`Dynamic_ALNS_RL34959.main(approach=0)`），不是 RL 线程。

文件：`codes/Dynamic_ALNS_RL34959.py:73` 的 `main()`（approach!=1 分支里有一个 `while True:` 大循环）

这个循环每次会：
1. 调一次 `Intermodal_ALNS_function(request_number_in_R)`  
2. 决定下一次的 `table_number`（也就是下一次要读的 Excel 文件 idx）

### 2.3 它是顺序读取还是随机读取？
**结论：严格按索引顺序读（没有 shuffle）。**

具体逻辑（`codes/Dynamic_ALNS_RL34959.py:92-118`）：

- 初始：`table_number = 0`
- 训练阶段（`dynamic_RL34959.implement == 0`）：  
  `table_number += 1`  
  → 0,1,2,3,... 递增
- 切到实施阶段（`dynamic_RL34959.implement == 1`）第一次：  
  - `table_number = 499`（只做一次）  
  - 然后每次 `table_number -= 1`  
  → 499,498,497,... 递减

> 这点非常重要：如果你的 mix 分界在 750（75/25），那实施阶段从 499 往下走 **永远落在“前 75%”那一段**；  
> 你观察到的“后期策略坍塌”更可能发生在**训练阶段 table_number 增长跨过分界**之后，而不是实施阶段。

### 2.4 每次读取几个文件、读多少数据？写死还是可变？
- **每个 episode（更准确说：每次 Intermodal_ALNS_function 调用）只读 1 个 Excel 文件**，文件由 `table_number` 决定。
- 但**一个 Excel 文件里有多少动态事件 sheet 是不固定的**：  
  生成脚本理论上最多写 `limit=50` 个事件，但会因以下原因减少：
  - `start_t < last_end` 会跳过（防止事件重叠）
  - `[loc, mode]` 重复会跳过
  - triggers 本身数量有限
- 所以：  
  - “文件数量/索引范围”基本写死为 0..999（代码中还有 clamp）  
  - “每个文件里事件数”是可变的（由触发器与过滤条件决定）

---

## 3) 消费审计：ALNS 如何读取/加载不确定性事件？

### 3.1 ALNS 读取文件的入口在哪？
两处你必须同时看：

1) **ALNS 内部决定 `data_path`**  
文件：`codes/Intermodal_ALNS34959.py`（动态=1 分支）  
- 关键代码：`table_number = Dynamic_ALNS_RL34959.table_number`（`codes/Intermodal_ALNS34959.py:13803`）
- 然后拼出路径：  
  `.../R{request_number_in_R}/Intermodal_EGS_data_dynamic_congestion{table_number}.xlsx`（`codes/Intermodal_ALNS34959.py:13806-13810`）

2) **外层驱动“什么时候触发事件”**  
文件：`codes/Dynamic_ALNS_RL34959.py` 的 `Intermodal_ALNS_function()`（`codes/Dynamic_ALNS_RL34959.py:12`）  
它会：
- 先跑一次 `Intermodal_ALNS34959.real_main(3, 0, request_number_in_R)` 让 ALNS 完成初始化并设置好 `data_path`
- 然后 `pd.ExcelFile(data_path)` + `pd.read_excel(Data, None)` 把所有 sheet 读出来
- 解析所有 `R_{r}_{time} (2)` sheet 的 time，得到 `unexpected_times`
- 最后按时间轴 for t in horizon：当 `t in unexpected_times` 时再调用 `real_main(3, t, request_number_in_R)` 推进仿真

**总结：ALNS 接收的“喂数据参数”本质只有：**
- `Dynamic_ALNS_RL34959.table_number`（决定读哪个 Excel 文件）
- `Intermodal_ALNS34959.request_number_in_R`（决定读哪个 R 目录）
- `Intermodal_ALNS34959.duration_type`（决定读哪个 target_folder 前缀）
它**没有拿到 dist_name/分布参数/来自哪一段**这类元信息。

### 3.2 RL 侧为何也会读取 Excel？
文件：`codes/dynamic_RL34959.py` 的 `get_state()`（`codes/dynamic_RL34959.py:253`）

它会用（同样的）：
- `table_number`（默认来自 `Dynamic_ALNS_RL34959.table_number`）
- `dynamic_t_begin`（事件开始时刻）
去读 Excel 的某一个事件 sheet：  
`R_{r}_{dynamic_t_begin} (2)`  
并取 `duration_length = end-start` 来映射 `severity_level`。

也就是说：**RL 的观测 severity 是“从文件里的 duration 反推出来的”**，但仍然没有分布参数。

---

## 4) 你现在缺的 Ground Truth，到底缺在哪里？

你缺的是“**这个 step 属于 mix 的哪一段（低压/高压）**”的标注。

- 生成时：脚本知道 `dist_name`，也知道“前多少行是 A，后多少行是 B”，但 **没有把这个信息写进文件**。
- 消费时：ALNS/RL 只读 `duration`，只知道数值，不知道“它是从哪个分布抽的”。

所以你在 `rl_trace.csv` 里只能看到观测（delay_tolerance、severity 等），而看不到“生成来源”。

---

## 5) 不改代码，能不能恢复每个 step 的“低压/高压”？
**可以恢复，而且精度是确定性的（前提：生成脚本没有 shuffle；当前确实没有）。**

### 5.1 你已经拥有恢复所需的两个信息
1. run 配置：`codes/logs/run_*/meta.json` 里有 `distribution`（你选择的 dist_name）
2. step 对应的文件 idx：`rl_trace.csv` 里有 `table_number`

### 5.2 恢复规则（核心公式）
假设：
- `total_files = 1000`（master 固定）
- `idx = table_number`

则对二段 mix：
- 75/25：`boundary=750`
- 50/50：`boundary=500`
- 25/75：`boundary=250`

Ground Truth 规则：
- `idx < boundary` → “第一段分布（前段）”
- `idx >= boundary` → “第二段分布（后段）”

对三段 mix（30/30/40）：
- `0 <= idx < 300` → 第一段
- `300 <= idx < 600` → 第二段
- `600 <= idx <= 999` → 第三段

### 5.3 “低压/高压”的含义如何对应到具体参数？
直接按生成代码对应即可（这就是 Ground Truth）：

- `normal_mix_8_80_*`：
  - 低压：Normal(8, 2)
  - 高压：Normal(80, 20)
- `normal_mix_80_8_*`：
  - 第一段：Normal(80, 20)
  - 第二段：Normal(8, 2)
- `lognormal_mix_8_80_*`：
  - 低压：LogNormal(mu=2, sigma=0.5)（理论均值≈8.37）
  - 高压：LogNormal(mu=4.4, sigma=0.5)（理论均值≈92.4）
- `lognormal_mix_80_8_*`：反过来
- `lognormal_mix_9_30_3_30_30_40`：
  - 第一段：LogNormal(mu=log(9)-0.125, sigma=0.5)（均值=9）
  - 第二段：LogNormal(mu=log(30)-0.125, sigma=0.5)（均值=30）
  - 第三段：LogNormal(mu=log(3)-0.125, sigma=0.5)（均值=3）

### 5.4 为什么你会觉得“现在看不出来”？
因为 `rl_trace.csv` 里不会写 `dist_component`（第一段/第二段），而你需要把 `table_number` 映射一下。

> 换句话说：Ground Truth 不在文件里、也不在日志列里，但它**在“生成方式 + idx”里**。  
> 这属于“可离线推断的 Ground Truth”。

---

## 6) 如果未来要彻底解决（建议从哪里改，怎么改？——仅建议，不实施）

你问“从 ALNS 入手还是从生成端入手”，我的判断：

### 6.1 最优解：从生成端入手（根因修复）
原因：**只有生成端知道 Ground Truth。**  
建议两种做法（二选一即可）：

A. 每个 `*.xlsx` 额外写一个 `meta` sheet（或 `info` sheet），字段例如：
- `dist_name`
- `component_id`（low/high 或 1/2/3）
- `component_params`（mu/sigma 或 mean/std）
- `idx`
- `total_files`
这样 ALNS/RL 只要读一次就能知道来源。

B. 生成一个“全局映射文件”（JSON/CSV）：
- `mapping.csv`: `idx, dist_name, component_id, params...`
优点：不用污染每个 Excel；缺点：需要运行时能找到 mapping 文件路径。

### 6.2 次优解：从 ALNS 入手（传播/记录）
如果你不想动生成文件格式，也可以：
- 在 ALNS 读取 `table_number` 时，根据 `dist_name` + `idx` 自己计算 `component_id`，然后把它写入 `state_reward_pairs` 并记录到日志
但这需要 ALNS 运行时能拿到 `dist_name`（现在 dist_name 主要存在 run 的 meta.json 和 master 变量里，ALNS 侧并不知道）。

### 6.3 不改代码的“现实方案”（你现在就能做）
写一个离线分析脚本：
- 读 `meta.json` 得到 `dist_name`
- 读 `rl_trace.csv` 得到 `table_number`
- 用上面第5节的边界规则新增列 `dist_component`、`dist_params`
- 然后你就能量化：
  - reward 随 component 的变化（是否跨边界后断崖）
  - action 分布随 component 的变化（策略是否在高压段塌缩）
  - severity 分布随 component 的变化（环境确实变难了吗）

---

## 7) 一个额外但非常关键的提醒（解释“策略坍塌”现象的前置条件）

由于数据是**按 idx 分段写入且按 idx 顺序喂给训练**：
- 如果训练步数（对应 processed tables）最终跨过 boundary（如 750），环境会发生**结构性突变**（低压→高压），这非常容易触发策略坍塌。
- 但如果你的训练很早就切到了 implement（例如只跑了前 100~200 个 table），那么训练可能根本没见到“后 25% 高压段”，此时所谓 mix 的后段对训练不产生影响。

所以在做“坍塌归因”之前，你必须先用 `table_number` 画出：
- 训练期间 table_number 的时间序列（是否跨过 boundary）
- 坍塌发生点对应的 `idx` 是否接近 boundary

这也是你提出 Ground Truth 的根因：**没有 component 标注时，你无法完成归因闭环**。

---

# 附：本次审计用到的关键代码定位
- 混合分布生成：`codes/generate_mixed_parallel.py:61`
- 生成单个 Excel 文件：`codes/generate_mixed_parallel.py:221`
- 文件命名模板：`codes/generate_mixed_parallel.py:225`
- master 调用生成器与并行仿真：`codes/Dynamic_master34959.py`（`run_generator/run_simulation`）
- ALNS 线程 table_number 调度：`codes/Dynamic_ALNS_RL34959.py:73`（特别是 `:92-118`）
- RL 从 Excel 计算 severity：`codes/dynamic_RL34959.py:253`（特别是 `:271-278`）
- ALNS 拼接 data_path 并读取：`codes/Intermodal_ALNS34959.py:13803-13810`
